{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4fef817",
   "metadata": {},
   "source": [
    "'''\n",
    "For the below dataset :\n",
    "|Product|  Store|Price|\n",
    "+-------+-------+-----+\n",
    "| Iphone|BestBuy|  100|\n",
    "| Iphone|Walmart|   90|\n",
    "| Iphone| Amazon|   95|\n",
    "|Samsung| Amazon|   80|\n",
    "|Samsung|Walmart|   85|\n",
    "|Samsung|BestBuy|   90|\n",
    "\n",
    "Write a Query to generate the output as below without using window functions:\n",
    "|Product|  Walmart_price|BestBuy_price|Amazon_price|Competitive_price|\n",
    "+-------+-------+-----+\n",
    "| Iphone|90|  100|  95| N\n",
    "| Samsung|85|  90|   80| Y\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92086d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Product|  Store|Price|\n",
      "+-------+-------+-----+\n",
      "| Iphone|BestBuy|  100|\n",
      "| Iphone|Walmart|   90|\n",
      "| Iphone| Amazon|   95|\n",
      "|Samsung|BestBuy|   90|\n",
      "|Samsung|Walmart|   85|\n",
      "|Samsung| Amazon|   80|\n",
      "+-------+-------+-----+\n",
      "\n",
      "+-------+-------------+-------------+------------+-----------------+\n",
      "|product|Walmart_price|BestBuy_price|Amazon_price|Competitive_price|\n",
      "+-------+-------------+-------------+------------+-----------------+\n",
      "|Samsung|           85|           90|          80|                Y|\n",
      "| Iphone|           90|          100|          95|                N|\n",
      "+-------+-------------+-------------+------------+-----------------+\n",
      "\n",
      "+-------+-------------+-------------+------------+-----------------+\n",
      "|Product|Walmart_price|BestBuy_price|Amazon_price|Competitive_price|\n",
      "+-------+-------------+-------------+------------+-----------------+\n",
      "|Samsung|           85|           90|          80|                Y|\n",
      "| Iphone|           90|          100|          95|                N|\n",
      "+-------+-------------+-------------+------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using Window Function\n",
    "import os, sys\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Competitive_Price\").getOrCreate()\n",
    "\n",
    "class AmazonInventory:\n",
    "    \n",
    "    def get_data(self):\n",
    "        columns = ['Product','Store','Price']\n",
    "        data = [\n",
    "            ('Iphone','BestBuy',100),\n",
    "            ('Iphone','Walmart',90),\n",
    "            ('Iphone','Amazon',95),\n",
    "            ('Samsung','BestBuy',90),\n",
    "            ('Samsung','Walmart',85),\n",
    "            ('Samsung','Amazon',80)\n",
    "        ]\n",
    "        inputDf = spark.createDataFrame(data, columns) \n",
    "        return inputDf\n",
    "    \n",
    "    def priceCheck(self, inputDf):\n",
    "        inputDf.createOrReplaceTempView('input')\n",
    "        \n",
    "        query = \"\"\"\n",
    "        with pivot_cte as (\n",
    "        select product, \n",
    "        sum(case when Store = 'Walmart' then Price else 0 end) as Walmart_price,\n",
    "        sum(case when Store = 'BestBuy' then Price else 0 end) as BestBuy_price,\n",
    "        sum(case when Store = 'Amazon' then Price else 0 end) as Amazon_price\n",
    "        from input\n",
    "        group by product)\n",
    "        \n",
    "        select product, Walmart_price, BestBuy_price, Amazon_price, case when A.rnk=1 then 'Y' else 'N' end as Competitive_price\n",
    "        from (\n",
    "        select product,Walmart_price, BestBuy_price, Amazon_price, dense_rank() over(order by Amazon_price) as rnk\n",
    "        from pivot_cte)A \n",
    "        \"\"\"\n",
    "        return spark.sql(query)\n",
    "    \n",
    "    def priceCheckPySpark(self, inputDf):\n",
    "        pivotDf = inputDf.groupBy('Product')\\\n",
    "        .agg(sum(when(col('Store')=='Walmart', col(\"Price\")).otherwise(0)).alias(\"Walmart_price\"),\n",
    "                 sum(when(col('Store')=='BestBuy', col(\"Price\")).otherwise(0)).alias(\"BestBuy_price\"),\n",
    "                 sum(when(col('Store')=='Amazon', col(\"Price\")).otherwise(0)).alias(\"Amazon_price\")\n",
    "                )\n",
    "        \n",
    "        # Rank the prices by Amazon_price\n",
    "        rank_df = pivotDf.withColumn(\"rnk\", dense_rank().over(Window.orderBy(col(\"Amazon_price\"))))\n",
    "        \n",
    "        # Select the required columns and calculate Competitive_price\n",
    "        result_df = rank_df.select('Product', 'Walmart_price','BestBuy_price', 'Amazon_price', when(col('rnk')==1,'Y').otherwise('N').alias('Competitive_price'))\n",
    "        \n",
    "        return result_df\n",
    "    \n",
    "obj = AmazonInventory()\n",
    "inputDf = obj.get_data()\n",
    "inputDf.show()\n",
    "outputDf = obj.priceCheck(inputDf)\n",
    "outputDf.show()\n",
    "outputDf = obj.priceCheckPySpark(inputDf)\n",
    "outputDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df340f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+-------------+------------+-----------------+\n",
      "|Product|Walmart_price|BestBuy_price|Amazon_price|Competitive_price|\n",
      "+-------+-------------+-------------+------------+-----------------+\n",
      "| Iphone|           90|          100|          95|                N|\n",
      "|Samsung|           85|           90|          80|                Y|\n",
      "+-------+-------------+-------------+------------+-----------------+\n",
      "\n",
      "+-------+-------------+-------------+------------+-----------------+\n",
      "|Product|BestBuy_Price|Walmart_Price|Amazon_Price|Competitive_price|\n",
      "+-------+-------------+-------------+------------+-----------------+\n",
      "| Iphone|          100|           90|          95|                N|\n",
      "|Samsung|           90|           85|          80|                Y|\n",
      "+-------+-------------+-------------+------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "spark = SparkSession.builder.master('local[*]').getOrCreate()\n",
    "class AmazonInventory:\n",
    "    def createData(self):\n",
    "        data = [\n",
    "            ('Iphone', 'BestBuy', 100),\n",
    "            ('Iphone', 'Walmart', 90),\n",
    "            ('Iphone', 'Amazon', 95),\n",
    "            ('Samsung', 'Amazon', 80),\n",
    "            ('Samsung', 'Walmart', 85),\n",
    "            ('Samsung', 'BestBuy', 90)\n",
    "        ]\n",
    "        schema = ['Product', 'Store', 'Price']\n",
    "        return spark.createDataFrame(data, schema)\n",
    "\n",
    "    #SQL approach\n",
    "    def priceCheck(self, inputDf):\n",
    "        inputDf.createOrReplaceTempView('input')\n",
    "        query = \"\"\"with pivot as (\n",
    "                select * from input pivot(\n",
    "                max(Price) for Store in ('Walmart' as Walmart_price, 'BestBuy' as BestBuy_price, 'Amazon' as Amazon_price)\n",
    "                ) ),\n",
    "                minPrice as (\n",
    "                select min(Price) as min_price, Product from input group by Product\n",
    "                )\n",
    "                select M1.*,\n",
    "                case when M1.Amazon_price = M2.min_price\n",
    "                    then 'Y'\n",
    "                    else 'N'\n",
    "                end as Competitive_price\n",
    "                from pivot M1 inner join minPrice M2\n",
    "                on M1.Product = M2.Product\n",
    "                order by M1.Product\n",
    "                \"\"\"\n",
    "        return spark.sql(query)\n",
    "\n",
    "    #PySpark approach\n",
    "    def amazonPriceCheck(self, inputDf):\n",
    "        minPricedf = inputDf.groupBy('Product').agg(min('Price').alias('Min_Price'))\n",
    "        pivotDf = inputDf.groupBy('Product').pivot('Store').max('Price')\n",
    "        resultDf = pivotDf.join(minPricedf, on='Product', how='inner')\\\n",
    "                        .withColumn('Competitive_price', when(col('Amazon').__eq__(col('Min_Price')), lit('Y')).otherwise(lit('N')))\\\n",
    "                        .select('Product', col('BestBuy').alias('BestBuy_Price'), col('Walmart').alias('Walmart_Price'), col('Amazon').alias('Amazon_Price'), 'Competitive_price')\\\n",
    "                        .orderBy('Product')\n",
    "        return resultDf\n",
    "\n",
    "ob = AmazonInventory()\n",
    "inputDf = ob.createData()\n",
    "\n",
    "resultDf = ob.priceCheck(inputDf)\n",
    "resultDf.show()\n",
    "\n",
    "resultDf = ob.amazonPriceCheck(inputDf)\n",
    "resultDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c72b3b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark-env",
   "language": "python",
   "name": "pyspark-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
