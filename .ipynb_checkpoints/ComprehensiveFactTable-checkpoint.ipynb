{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "910cfb6e",
   "metadata": {},
   "source": [
    "'''\n",
    "Create a Comprehensive Fact Table\n",
    "\n",
    "Given two input files:\n",
    "- employee.csv with columns: employee_id, department, salary\n",
    "- employee_personal.csv with columns: employee_id, first_name, last_name, DOB, state, country\n",
    "\n",
    "Write transformations to create employee_fact with columns:\n",
    "- employee_id\n",
    "- employee_full_name\n",
    "- department\n",
    "- salary\n",
    "- Salary_Diff_to_reach_highest_sal\n",
    "- DOB\n",
    "- state\n",
    "- country\n",
    "- age\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82ec9ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+------+\n",
      "|employee_id|department|salary|\n",
      "+-----------+----------+------+\n",
      "|          1|        HR| 15000|\n",
      "|          2|        IT| 18000|\n",
      "|          3|        HR| 20000|\n",
      "|          4|        IT| 25000|\n",
      "|          5|     ADMIN| 12000|\n",
      "+-----------+----------+------+\n",
      "\n",
      "+-----------+----------+---------+----------+---------+-------+\n",
      "|employee_id|first_name|last_name|       DOB|    state|country|\n",
      "+-----------+----------+---------+----------+---------+-------+\n",
      "|          1|     Rohit|   Khanna|1995-12-10|    Delhi|     IN|\n",
      "|          2|     Arjun|      Rao|1993-10-10|  Chennai|     IN|\n",
      "|          3|   Kuldeep|     Nair|1994-02-20|    Delhi|     IN|\n",
      "|          4|     Viraj|  Khaskar|1995-03-19|Bengalore|     IN|\n",
      "|          5|    Aditya|     Paul|1996-06-12|   Mumbai|     IN|\n",
      "+-----------+----------+---------+----------+---------+-------+\n",
      "\n",
      "+-----------+------------------+----------+------+-----------+----------+---------+-------+---+\n",
      "|employee_id|employee_full_name|department|salary|salary_diff|       DOB|    state|country|age|\n",
      "+-----------+------------------+----------+------+-----------+----------+---------+-------+---+\n",
      "|          1|      Rohit Khanna|        HR| 15000|      10000|1995-12-10|    Delhi|     IN| 29|\n",
      "|          2|         Arjun Rao|        IT| 18000|       7000|1993-10-10|  Chennai|     IN| 31|\n",
      "|          3|      Kuldeep Nair|        HR| 20000|       5000|1994-02-20|    Delhi|     IN| 30|\n",
      "|          4|     Viraj Khaskar|        IT| 25000|          0|1995-03-19|Bengalore|     IN| 29|\n",
      "|          5|       Aditya Paul|     ADMIN| 12000|      13000|1996-06-12|   Mumbai|     IN| 28|\n",
      "+-----------+------------------+----------+------+-----------+----------+---------+-------+---+\n",
      "\n",
      "+-----------+------------------+----------+------+-----------+----------+---------+-------+---+\n",
      "|employee_id|employee_full_name|department|salary|salary_diff|       DOB|    state|country|age|\n",
      "+-----------+------------------+----------+------+-----------+----------+---------+-------+---+\n",
      "|          1|      Rohit Khanna|        HR| 15000|      10000|1995-12-10|    Delhi|     IN| 29|\n",
      "|          2|         Arjun Rao|        IT| 18000|       7000|1993-10-10|  Chennai|     IN| 31|\n",
      "|          3|      Kuldeep Nair|        HR| 20000|       5000|1994-02-20|    Delhi|     IN| 30|\n",
      "|          4|     Viraj Khaskar|        IT| 25000|          0|1995-03-19|Bengalore|     IN| 29|\n",
      "|          5|       Aditya Paul|     ADMIN| 12000|      13000|1996-06-12|   Mumbai|     IN| 28|\n",
      "+-----------+------------------+----------+------+-----------+----------+---------+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from datetime import date\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import concat, lit, first, col\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRVIER_PYTHON'] = sys.executable\n",
    "\n",
    "spark = SparkSession.builder.master('local[*]').appName('ComprehensiveFact').getOrCreate()\n",
    "\n",
    "\n",
    "class ComprehensiveFact:\n",
    "    \n",
    "    def createEmployeeData(self):\n",
    "        data = [\n",
    "            (1, 'HR', 15000),\n",
    "            (2, 'IT', 18000),\n",
    "            (3, 'HR', 20000),\n",
    "            (4, 'IT', 25000),\n",
    "            (5, 'ADMIN', 12000)\n",
    "        ]\n",
    "\n",
    "        columns = ['employee_id', 'department', 'salary']\n",
    "        return spark.createDataFrame(data, columns)\n",
    "\n",
    "    def createPersonalData(self):\n",
    "        data = [\n",
    "            (1, 'Rohit', 'Khanna', date(1995, 12, 10), 'Delhi', 'IN'),\n",
    "            (2, 'Arjun', 'Rao', date(1993, 10, 10), 'Chennai', 'IN'),\n",
    "            (3, 'Kuldeep', 'Nair', date(1994, 2, 20), 'Delhi', 'IN'),\n",
    "            (4, 'Viraj', 'Khaskar', date(1995, 3, 19), 'Bengalore', 'IN'),\n",
    "            (5, 'Aditya', 'Paul', date(1996, 6, 12), 'Mumbai', 'IN'),\n",
    "        ]\n",
    "\n",
    "        columns = ['employee_id', 'first_name', 'last_name', 'DOB', 'state', 'country']\n",
    "        return spark.createDataFrame(data, columns)\n",
    "    \n",
    "    def employeeFactSql(self, employee_df, employee_personal_df):\n",
    "        \n",
    "        employee_df.createOrReplaceTempView('employee')\n",
    "        employee_personal_df.createOrReplaceTempView('employee_personal')\n",
    "        query = '''\n",
    "        select ep.employee_id, \n",
    "        concat(ep.first_name,' ', ep.last_name) as employee_full_name,\n",
    "        e.department,\n",
    "        e.salary,\n",
    "        (select max(salary) from employee) - e.salary as salary_diff,\n",
    "        DOB,\n",
    "        state,\n",
    "        country,\n",
    "        year(current_date()) - year(DOB) as age\n",
    "        from employee_personal ep inner join employee e\n",
    "        on ep.employee_id = e.employee_id\n",
    "        \n",
    "        '''  \n",
    "        return spark.sql(query) \n",
    "        \n",
    "    def employeeFactSpark(self, employee_df, employee_personal_df):\n",
    "        \n",
    "        max_salary = employee_df.select('salary').agg(max('salary')).first()[0]\n",
    "        \n",
    "        merge_df = employee_personal_df.alias('ep').join(employee_df.alias('e'), on='employee_id', how='inner')\\\n",
    "        .withColumn('employee_full_name', concat('ep.first_name',lit(' '), 'ep.last_name'))\\\n",
    "        .withColumn('salary_diff',max_salary - col('e.salary'))\\\n",
    "        .withColumn('age', year(current_date()) - year(col('DOB')))\n",
    "        \n",
    "        \n",
    "        result_df = merge_df.select(col('employee_id'),\n",
    "        col('employee_full_name'),\n",
    "        col('department'),\n",
    "        col('salary'),\n",
    "        col('salary_diff'),\n",
    "        col('DOB'),\n",
    "        col('state'),\n",
    "        col('country'),\n",
    "        col('age')\n",
    "        )\n",
    "        \n",
    "        return result_df\n",
    "    \n",
    "obj = ComprehensiveFact()\n",
    "employee_df = obj.createEmployeeData()\n",
    "employee_personal_df = obj.createPersonalData()\n",
    "employee_df.show()\n",
    "employee_personal_df.show()\n",
    "result_df = obj.employeeFactSql(employee_df, employee_personal_df)\n",
    "result_df.show()\n",
    "result_df = obj.employeeFactSpark(employee_df, employee_personal_df)\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c42717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark-env",
   "language": "python",
   "name": "pyspark-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
