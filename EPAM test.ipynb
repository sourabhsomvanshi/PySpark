{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca68dec2",
   "metadata": {},
   "source": [
    "-- Implement your solution here\n",
    "\n",
    "with player_details as (\n",
    "select first_player as player_id,first_score as player_score\n",
    "from matches\n",
    "union \n",
    "select second_player as player_id,second_score as player_score\n",
    "from matches),\n",
    "\n",
    "player_total_score as (\n",
    "select player_id, sum(player_score) as player_score\n",
    "from player_details \n",
    "group by player_id),\n",
    "\n",
    "player_group as (\n",
    "select p2.group_id, p2.player_id, p1.player_score, row_number() over (partition by p2.group_id order by p1.player_score desc, p2.player_id asc) as row_no\n",
    "from player_total_score as p1 right join players as p2\n",
    "on p1.player_id=p2.player_id\n",
    ")\n",
    "\n",
    "select group_id, player_id as winner_id\n",
    "from player_group\n",
    "where row_no=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69053843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- council: string (nullable = true)\n",
      " |-- county: string (nullable = true)\n",
      " |-- council_type: string (nullable = false)\n",
      " |-- avg_price_nov_2019: double (nullable = true)\n",
      " |-- sales_volume_sep_2019: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit, round\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "class CouncilsJob:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.spark_session = (SparkSession.builder\n",
    "                                          .master(\"local[*]\")\n",
    "                                          .appName(\"EnglandCouncilsJob\")\n",
    "                                          .getOrCreate())\n",
    "        self.input_directory = \"data\"\n",
    "\n",
    "    def extract_councils(self):\n",
    "        district_councils_df = self.spark_session.read.csv(f'{self.input_directory}/england_councils/district_councils.csv', header=True)\n",
    "        london_boroughs_df  = self.spark_session.read.csv(f'{self.input_directory}/england_councils/london_boroughs.csv', header=True)\n",
    "        metropolitan_districts_df  = self.spark_session.read.csv(f'{self.input_directory}/england_councils/metropolitan_districts.csv', header=True)\n",
    "        unitary_authorities_df  = self.spark_session.read.csv(f'{self.input_directory}/england_councils/unitary_authorities.csv', header=True)\n",
    "        \n",
    "        district_councils_df = district_councils_df.withColumn('council_type', lit('District Council'))\n",
    "        london_boroughs_df = london_boroughs_df.withColumn('council_type', lit('London Borough'))\n",
    "        metropolitan_districts_df = metropolitan_districts_df.withColumn('council_type', lit('Metropolitan District'))\n",
    "        unitary_authorities_df = unitary_authorities_df.withColumn('council_type', lit('Unitary Authority'))\n",
    "\n",
    "        df1 =  district_councils_df.union(london_boroughs_df)\n",
    "        df2 = df1.union(metropolitan_districts_df)\n",
    "        councils_df = df2.union(unitary_authorities_df)\n",
    "        return councils_df\n",
    "\n",
    "    def extract_avg_price(self):\n",
    "        property_avg_price_df = self.spark_session.read.csv(f'{self.input_directory}/property_avg_price.csv', header=True)\n",
    "        avg_price_df = property_avg_price_df.select('local_authority','avg_price_nov_2019')\n",
    "        avg_price_df = avg_price_df.withColumn('avg_price_nov_2019', round(avg_price_df.avg_price_nov_2019,1))\n",
    "        avg_price_df = avg_price_df.withColumnRenamed('local_authority','council')\n",
    "        return avg_price_df\n",
    "\n",
    "    def extract_sales_volume(self):\n",
    "        property_sales_volume_df = self.spark_session.read.csv(f'{self.input_directory}/property_sales_volume.csv', header=True)\n",
    "        sales_volume_df = property_sales_volume_df.select('local_authority','sales_volume_sep_2019')\n",
    "        sales_volume_df = sales_volume_df.withColumn('sales_volume_sep_2019', sales_volume_df.sales_volume_sep_2019.cast(IntegerType()))\n",
    "        sales_volume_df = sales_volume_df.withColumnRenamed('local_authority','council')\n",
    "        return sales_volume_df\n",
    "\n",
    "    def transform(self, councils_df, avg_price_df, sales_volume_df):\n",
    "        avg_price_df = avg_price_df.withColumnRenamed('council', 'avg_council')\n",
    "        sales_volume_df = sales_volume_df.withColumnRenamed('council', 'sales_council')\n",
    "        merged_df1 = councils_df.join(avg_price_df, councils_df['council']==avg_price_df['avg_council'], how='left')\n",
    "        merged_df2 = merged_df1.join(sales_volume_df, merged_df1['council']==sales_volume_df['sales_council'], how='left')\n",
    "        output_df = merged_df2.select('council','county','council_type','avg_price_nov_2019','sales_volume_sep_2019')\n",
    "        return output_df\n",
    "\n",
    "    def run(self):\n",
    "        return self.transform(self.extract_councils(), self.extract_avg_price(), self.extract_sales_volume())\n",
    "        \n",
    "obj = CouncilsJob()\n",
    "#outputdf = obj.extract_councils()\n",
    "#outputdf = obj.extract_avg_price()\n",
    "#outputdf = obj.extract_sales_volume()\n",
    "outputdf = obj.run()\n",
    "#outputdf.count()\n",
    "#outputdf.show()\n",
    "outputdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44747010",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark-env",
   "language": "python",
   "name": "pyspark-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
